{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b4ce2e7",
   "metadata": {},
   "source": [
    "## MuraMed: A Revolution in Medical Diagnostics\n",
    "---\n",
    "\n",
    "**MuraMed** is an innovative healthcare technology company that aims to revolutionize medical diagnostics with a focus on radiographs (X-Ray images). In the intricate landscape of today's healthcare, the company addresses the vital need for accurate, efficient, and swift diagnosis. MuraMed's specialization lies in detecting bone abnormalities, and it offers an AI-powered diagnostic system tailored for healthcare professionals. This initiative is particularly significant for radiology, a field often challenged by the timeliness and precision of X-ray image interpretation. A brief description of our **MuraMed's Business Case** follows below.\n",
    "\n",
    "In the domain of medical diagnostics, particularly in the field of **bone abnormality detection**, MuraMed has established a unique presence for itself. Using advanced AI technologies, MuraMed has developed a diagnostic system that is highly effective. This system doesn't just represent a technological advancement; it signifies a shift in how musculoskeletal conditions are diagnosed, making it faster and more accurate. This initiative has the potential to improve patient outcomes and overall well-being significantly for those with musculoskeletal disorders.\n",
    "\n",
    "However, **MuraMed**'s expertise extends beyond bone abnormality detection; it also encompasses a broader revolution in **radiology**. The company is at the forefront of integrating Artificial Intelligence into this critical medical field, offering solutions that address the challenges faced by healthcare providers. The AI-driven approach adopted by MuraMed reduces the inefficiencies and human errors associated with traditional diagnostic methods. By providing radiologists and orthopedic doctors with user-friendly AI tools, MuraMed ensures that healthcare providers can make quick, well-informed decisions, ultimately enhancing patient care.\n",
    "\n",
    "The **versatility** of MuraMed's technological platform is another key feature. The application is designed not only to meet the needs of experienced medical professionals but also to extend its benefits to a wider audience, including athletes, teachers, and physiotherapists. These individuals can use this platform for early detection and intervention of musculoskeletal issues. This inclusive approach democratizes diagnostic capabilities, making proactive healthcare more accessible. Through this multifaceted approach, **MuraMed** is set to make a lasting impact across various sectors, from specialized medicine to community healthcare and beyond.\n",
    "\n",
    "\n",
    "\n",
    "<figure>\n",
    "  <img src=\"./Figures/muramed_logo.png\" alt=\"MuraMed Logo\" style=\"width:35%\">\n",
    "  <figcaption style=\"text-align:center;\">MuraMed: A Revolution in Medical Diagnostics</figcaption>\n",
    "</figure>\n",
    "\n",
    "\n",
    "When it comes to **MuraMed**'s long-term aspirations, the company's **Mission and Vision** serve as guiding lights. The company is not merely focused on providing AI-powered diagnostic solutions; it has a grander vision of impacting global healthcare. Specifically, MuraMed aspires to make healthcare access equitable, concentrating its efforts on areas facing a dire shortage of skilled radiologists. This vision is not restricted to large healthcare facilities but extends to smaller clinics and even transcends the boundaries of the traditional healthcare industry. By integrating advanced AI algorithms with a specialized focus on bone abnormalities and a versatile application range, MuraMed aims to revolutionize medical diagnostics in an unparalleled manner. Through these initiatives, the company is set to bring about monumental changes that will redefine the landscape of healthcare, making quality diagnostic services accessible and affordable to all.\n",
    "\n",
    "Similarly, the intrinsic **Value of MuraMed's Research** cannot be overstated. The company's research initiatives are designed to make substantial contributions across multiple domains, including healthcare, technology, business, and innovation. This multi-disciplinary approach not only highlights the company's commitment to improving patient care but also signals its intent to push the boundaries of existing technology. **MuraMed** is invested in creating a harmonious blend of technology and healthcare, using AI as a tool to bridge gaps and address inefficiencies in the current medical systems. Consequently, the company's research serves as a catalyst for business growth, as it opens up new avenues for expansion and partnerships. \n",
    "\n",
    "In summary, both the mission and the research values of **MuraMed** underscore its commitment to being more than just a healthcare technology company. It strives to be a change-maker in the industry, leveraging technology to address crucial gaps in healthcare accessibility and quality. By doing so, MuraMed aims to foster not just business growth but also societal advancement, setting new benchmarks in healthcare, technology, and innovation.\n",
    "\n",
    "---\n",
    "\n",
    "For further insights into **MuraMed**'s groundbreaking work, one can refer to the comprehensive document: *[MuraMed_Documentation.pdf](./MuraMed_Documentation.pdf)*.\n",
    "\n",
    "While the current analysis will be done on [Jupyter Notebook](http://jupyter.org/) and in [Python 3.10.0](https://www.python.org/downloads/release/python-3100/).\n",
    "\n",
    "---\n",
    "\n",
    "####  Team members:\n",
    "\n",
    "---\n",
    "> Dimitra Diamanti <br />\n",
    "> Academic ID: f2822209 <br />\n",
    "> MSc Business Analytics 2022-2023 FT <br />\n",
    "> Athens University of Economics and Business <br />\n",
    "> dtdiamanti@gmail.com, dim.diamanti@aueb.gr\n",
    "\n",
    "---\n",
    "\n",
    "> Dimitrios Matsanganis <br />\n",
    "> Academic ID: f2822212 <br />\n",
    "> MSc Business Analytics 2022-2023 FT <br />\n",
    "> Athens University of Economics and Business <br />\n",
    "> dmatsanganis@gmail.com, dim.matsanganis@aueb.gr\n",
    "\n",
    "---\n",
    "\n",
    "> Foteini Nefeli Nouskali <br />\n",
    "> Academic ID: f2822213 <br />\n",
    "> MSc Business Analytics 2022-2023 FT <br />\n",
    "> Athens University of Economics and Business <br />\n",
    "> fn.nouskali@gmail.com, fot.nouskali@aueb.gr\n",
    "\n",
    "---\n",
    "\n",
    "> Hegla Eva Ruci <br />\n",
    "> Academic ID: f2822219 <br />\n",
    "> MSc Business Analytics 2022-2023 FT <br />\n",
    "> Athens University of Economics and Business <br />\n",
    "> eva.14rou@gmail.com, heg.ruci@aueb.gr\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e6abbd",
   "metadata": {},
   "source": [
    "### Detailed Overview of MuraMed's Business Case\n",
    "\n",
    "---\n",
    "\n",
    "As mentioned briefly above, **MuraMed's Business Case** is a comprehensive blueprint that outlines the company's strategic approach to revolutionize medical diagnostics, specifically focusing on musculoskeletal radiographs. By leveraging advanced AI and deep learning technologies, MuraMed aims to address critical gaps in the healthcare, sports, and workplace sectors. The business case is built around three core pillars, each designed to cater to the unique needs of different demographic groups and industries.\n",
    "\n",
    "\n",
    "#### The Three Core Pillars of MuraMed's Business Case\n",
    "\n",
    "1. **MuraMed: Healthcare Edition**\n",
    "    - This pillar serves as the cornerstone of MuraMed's business model, targeting traditional healthcare facilities like hospitals and clinics. By focusing on specific areas like the hand, elbow, and shoulder, it aims to bring unparalleled precision to musculoskeletal radiograph analysis. The platform's AI-backed second opinion feature is particularly beneficial for radiologists and orthopedic doctors, enhancing diagnostic accuracy and efficiency. Furthermore, its seamless integration capabilities with existing hospital systems make it an invaluable asset in accelerating diagnostic services.\n",
    "\n",
    "\n",
    "2. **MuraMed: School & Sports Organization Edition**\n",
    "    - Tailored for the unique needs of young athletes and students, this pillar extends MuraMed's reach beyond conventional healthcare settings. By offering real-time detection of musculoskeletal abnormalities, it plays a transformative role in sports medicine. The platform is designed to be versatile, applicable in sports activities where hand injuries are common, such as basketball, volleyball, and handball. With its potential to positively impact the health and performance of young athletes, this pillar significantly broadens MuraMed's market reach.\n",
    "\n",
    "\n",
    "3. **MuraMed: Workplace Edition**\n",
    "    - Addressing the growing concern of work-related musculoskeletal disorders (MSDs), this pillar is designed for a broad range of industries. From manual labor-intensive sectors to office-based jobs, it aims to tackle the unique challenges each profession faces concerning MSDs. The platform offers regular employee check-ups and ergonomic evaluations as preventive measures. Supported by alarming statistics from the U.S. Department of Labor, this pillar emphasizes the need for early detection and management of hand and upper limb conditions, thereby promoting healthier workplaces.\n",
    "\n",
    "---\n",
    "\n",
    "#### Strategic Importance\n",
    "\n",
    "The strategic alignment of these three pillars enables MuraMed to offer specialized solutions that address the nuanced needs of various sectors. From healthcare professionals requiring precise and rapid diagnostics to sports organizations and workplaces seeking to enhance well-being and performance, MuraMed's comprehensive business case sets a new benchmark in the realm of musculoskeletal health diagnostics.\n",
    "\n",
    "By integrating cutting-edge AI technologies with sector-specific requirements, MuraMed's business case presents a multifaceted approach to improve diagnostic accuracy, efficiency, and accessibility across different verticals. It not only targets the immediate needs of these sectors but also positions the company for future growth and innovation in the rapidly evolving landscape of medical diagnostics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6b3958",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "### Mura Dataset\n",
    "\n",
    "At the core of **MuraMed**'s capabilities is its reliance on extensive datasets provided by Stanford University, known as the MURA datasets (combine for different parts of the human body). These datasets are a rich library of manually reviewed and labeled musculoskeletal radiographs, focusing on multiple body parts such as the wrist, shoulder, elbow, and more. The datasets form the backbone of MuraMed's AI algorithms, enabling them to accurately identify normal or abnormal characteristics in X-ray studies. More information about the MURA dataset can be found at [Stanford's ML site](https://stanfordmlgroup.github.io/competitions/mura/) or at [Kaggle](https://www.kaggle.com/datasets/cjinny/mura-v11/download?datasetVersionNumber=1). \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<figure>\n",
    "  <img src=\"./Figures/muramed1.png\" alt=\"Official Stanford ML Logo\" style=\"width:30%\">\n",
    "  <figcaption style=\"text-align:center;\">Figure 1. Official Stanford ML Logo</figcaption>\n",
    "</figure>\n",
    "<br>\n",
    "\n",
    "Currently, our algorithms are designed to *focus on the aforementioned body parts*. Their primary task is to determine whether an X-ray study of these areas exhibits normal or abnormal characteristics. In the near future, we plan to expand our AI capabilities to involve a broader spectrum of anatomical regions , further enhancing our diagnostic capabilities.\n",
    "\n",
    "<br><br>\n",
    "<figure>\n",
    "  <img src=\"./Figures/muramed2.jpg\" alt=\"A detailed image showcasing the anatomical parts included in the Mura Dataset\" style=\"width:15%\">\n",
    "  <figcaption style=\"text-align:center;\">Figure 2. A detailed image showcasing the anatomical parts included in the Mura Dataset</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ec4f59",
   "metadata": {},
   "source": [
    "### Moving from Business Vision to Technical Implementation - Roadmap\n",
    "---\n",
    "Having articulated the core objectives and innovative prospects of our business idea, it is imperative to transition into the phase of technical implementation. To ensure clarity, facilitate seamless execution, and enhance stakeholder understanding, we present the following roadmap.\n",
    "\n",
    "oxi auto allo :( den douleuei\n",
    "- [**1. Libraries & Installation Guidelines**](#libraries_installation_guidelines)\n",
    "\n",
    "- [**2. Data Handling**](#data_handling)\n",
    "  - \n",
    "  - [**2.1. Load the Dataset**](#load_dataset)\n",
    "  - [**2.2. Data Preparation Steps**](#data_preparation_steps)\n",
    "  - [**2.3. Data Cleaning**](#data_cleaning)\n",
    "  \n",
    "- [**3. CNN for Bone Abnormality Detection**](#cnn)\n",
    "  - [**3.1. Model Architecture**](#model_architecture)\n",
    "  - [**3.2. Metrics**](#metrics)\n",
    "  - [**3.3. Model Training**](#model_training)\n",
    "  - [**3.4. Model Evaluation**](#model_evaluation)\n",
    "\n",
    "This structured pathway serves as our blueprint for translating MuraMed's business vision into a scalable, operational model. It encompasses everything from initial setup to sophisticated model evaluations, thereby providing a comprehensive guide for all involved parties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f77b057",
   "metadata": {},
   "source": [
    "### Libraries & Installation Guidlines\n",
    "---\n",
    "\n",
    "In this Jupyter Notebook, we focus on leveraging a robust set of Python libraries tailored for data manipulation, statistical analysis, machine learning, and deep learning. These libraries are integral to the data science pipeline, aiding in various tasks from data preprocessing to model evaluation. Below is an in-depth look at each library's role, along with their respective documentation links for further exploration.\n",
    "\n",
    "- **Pandas**: Employed for data manipulation and analysis, it serves as the initial point for data loading and transformation.\n",
    "  - [Pandas Documentation](https://pandas.pydata.org/docs/)\n",
    "  \n",
    "  \n",
    "- **NumPy**: Essential for numerical operations, it works hand-in-hand with Pandas for data transformation and manipulation.\n",
    "  - [NumPy Documentation](https://numpy.org/doc/)\n",
    "  \n",
    "  \n",
    "- **Matplotlib**: Utilized for data visualization, it aids in plotting graphs and charts to better understand the dataset.\n",
    "  - [Matplotlib Documentation](https://matplotlib.org/stable/contents.html)\n",
    "  \n",
    "  \n",
    "- **Seaborn**: An extension of Matplotlib, used for more complex visualizations, and it offers a higher level of abstraction.\n",
    "  - [Seaborn Documentation](https://seaborn.pydata.org/)\n",
    "  \n",
    "  \n",
    "- **Scikit-learn**: Provides a wide range of machine learning algorithms and is used here for splitting datasets into training and test sets.\n",
    "  - [Scikit-learn Documentation](https://scikit-learn.org/stable/)\n",
    "  \n",
    "  \n",
    "- **TensorFlow**: The backbone for deep learning tasks, it offers a comprehensive and flexible ecosystem for building and deploying machine learning models.\n",
    "  - [TensorFlow Documentation](https://www.tensorflow.org/guide)\n",
    "  \n",
    "  \n",
    "- **TensorFlow Addons**: An additional package that extends TensorFlow functionalities, providing extra layers and metrics.\n",
    "  - [TensorFlow Addons Documentation](https://www.tensorflow.org/addons/overview)\n",
    "  \n",
    "  \n",
    "By integrating these libraries, we aim to build a cohesive and efficient pipeline for developing advanced machine learning models for medical diagnostics as mentioned above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "254e89ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas version: 1.5.3\n",
      "NumPy version: 1.24.1\n",
      "Matplotlib version: 3.6.3\n",
      "Seaborn version: 0.12.2\n",
      "Scikit-learn version: 1.2.1\n",
      "Tensorflow version: 2.13.0\n"
     ]
    }
   ],
   "source": [
    "# Utilized Libraries of the current analysis.\n",
    "\n",
    "# Basic Data Manipulation Libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "print(f'Pandas version: {pd.__version__}')\n",
    "print(f'NumPy version: {np.__version__}')\n",
    "\n",
    "# Data Visualization Libraries.\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "print(f'Matplotlib version: {matplotlib.__version__}')\n",
    "print(f'Seaborn version: {sns.__version__}')\n",
    "%matplotlib inline\n",
    "\n",
    "# Utilities.\n",
    "import gc  # Garbage collection.\n",
    "import zipfile  # For handling zip files.\n",
    "import time  # For timing operations.\n",
    "import random  # For generating random numbers.\n",
    "\n",
    "# Scikit-learn for Model Preparation.\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "print(f'Scikit-learn version: {sklearn.__version__}')\n",
    "\n",
    "# TensorFlow and Keras for Model Building, Training, and Evaluation.\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress TensorFlow logging.\n",
    "\n",
    "# Use the os. environ module to set the TF_CPP_MIN_LOG_LEVEL environment variable to 3 to \n",
    "# disable/suppress all tensorflow warnings.\n",
    "# When the environment variable is set to 3 , info, warning and error messages are not logged.\n",
    "\n",
    "# Suppress specific TensorFlow Addons warnings.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='tensorflow_addons')  # Suppress TFA UserWarnings.\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.random import set_seed  # For reproducibility.\n",
    "from tensorflow.keras import backend as K  # Keras backend.\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Data augmentation.\n",
    "from tensorflow.keras.optimizers import Adam  # Optimizer.\n",
    "from tensorflow.keras.applications import VGG19  # VGG19 model.\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPool2D, Dropout, Flatten, Dense  # Layers.\n",
    "from tensorflow.keras.models import Model  # Model class.\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint  # Callbacks.\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input  # Preprocessing.\n",
    "from tensorflow.keras.regularizers import l2  # L2 regularization.\n",
    "from tensorflow.keras.utils import plot_model  # For plotting model architecture.\n",
    "\n",
    "# Metrics for Model Evaluation.\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall, AUC\n",
    "from tensorflow_addons.metrics import CohenKappa\n",
    "\n",
    "# Scikit-learn Metrics for Model Evaluation.\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, cohen_kappa_score\n",
    "\n",
    "print(f'Tensorflow version: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18fa539",
   "metadata": {},
   "source": [
    "From the above, the libraries used are the followings:\n",
    "\n",
    "- **Pandas**: Version 1.5.3\n",
    "- **NumPy**: Version 1.24.1\n",
    "- **Matplotlib**: Version 3.6.3\n",
    "- **Seaborn**: Version 0.12.2\n",
    "- **Scikit-learn**: Version 1.2.1\n",
    "- **TensorFlow**: Version 2.13.0\n",
    "\n",
    "If we would like to be more specific we can notate the followings:\n",
    "\n",
    "- **Pandas**: The environment utilizes Pandas version **1.5.3**, which provides robust capabilities for data manipulation and analysis.\n",
    "  \n",
    "- **NumPy**: The version in use is **1.24.1**, essential for a variety of numerical operations. It complements Pandas in data transformation and manipulation.\n",
    "\n",
    "- **Matplotlib**: The current version is **3.6.3**, offering a wide array of functionalities for data visualization.\n",
    "\n",
    "- **Seaborn**: Version **0.12.2** is installed, extending Matplotlib's functionalities for more advanced data visualizations.\n",
    "\n",
    "- **Scikit-learn**: The environment leverages Scikit-learn version **1.2.1**, a comprehensive library for machine learning tasks such as data splitting, model training, and evaluation.\n",
    "\n",
    "- **TensorFlow**: Version **2.13.0** forms the backbone for all deep learning tasks, offering a comprehensive and flexible platform for building, training, and deploying machine learning models. Furthermore, **TensorFlow** serves as the cornerstone of our deep learning applications. Developed by Google, TensorFlow offers a comprehensive ecosystem for deploying machine learning models, including those based on neural networks. The library is particularly optimized for high-performance numerical computation, a crucial feature for medical image analysis.\n",
    "\n",
    "\n",
    "Overall, these versions indicate a well-updated environment, suitable for our tasks.\n",
    "\n",
    "---\n",
    "\n",
    "**_Important Note 1 - UserWarning:_** You may receive a UserWarning that indicates that TensorFlow Addons (TFA) has stopped development of new features and is in maintenance mode until May 2024. This means it's advisable to transition to other TensorFlow community libraries for new features or functions that were previously covered by TFA (this warning has been suppressed with filterwarnings). \n",
    "\n",
    "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
    "\n",
    "**_Important Note 2 - TensorFlow and Installation:_** The installation of Tensorflow sometimes can be tricky, therefore to install Tensorflow through `pip` you need to run the following commands:\n",
    "\n",
    "```bash\n",
    "pip install tensorflow\n",
    "```\n",
    "\n",
    "To additionally install TensorFlow Addons:\n",
    "\n",
    "```bash\n",
    "pip install tensorflow-addons\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e68aecf",
   "metadata": {},
   "source": [
    "### MURA Dataset\n",
    "---\n",
    "\n",
    "The **MURA dataset**, an acronym for *Musculoskeletal Radiographs*, is a large-scale, specialized collection of digital X-ray images that was officially released by **Stanford University** in the year 2017. This dataset is instrumental to the medical community as it comprises an extensive array of over **40,000 digital X-ray images** spanning **seven different anatomical regions**, namely the wrist, elbow, shoulder, finger, hip, knee, and ankle. The **MURA dataset** is structured into two primary folders, namely **\"train\"** and **\"valid\"**, each containing datasets relevant to their respective categories. In total, the MURA dataset comprises approximately **41,000 images** derived from around **15,000 distinct studies** (patients). These images are distributed across both the training and validation sets. The dataset is thoughtfully curated to encompass a wide range of medical conditions, allowing for comprehensive evaluation and training of diagnostic models.\n",
    "\n",
    "Within this dataset, there are **9,000** studies representing **normal** or negative conditions, serving as essential reference points for identifying healthy anatomical structures. Additionally, there are **6,000** studies representing **abnormal** or positive conditions, encapsulating a variety of pathological findings that require accurate and timely detection. The typical image resolution in the MURA dataset is 500 x 500 pixels. More information about the MURA dataset can be found at [Stanford's ML site](https://stanfordmlgroup.github.io/competitions/mura/) or at [Kaggle](https://www.kaggle.com/datasets/cjinny/mura-v11/download?datasetVersionNumber=1). \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<figure>\n",
    "  <img src=\"./Figures/muramed3.png\" alt=\"MURA Dataset Instances\" style=\"width:35%\">\n",
    "  <figcaption style=\"text-align:center;\">Figure 3. MURA Dataset Instances</figcaption>\n",
    "</figure>\n",
    "<br>\n",
    "\n",
    "Over the years, the MURA dataset has emerged as a *benchmark standard* for assessing the efficacy of deep learning models in the domain of musculoskeletal radiography. It has been extensively employed in numerous research studies and competitions, serving as the foundation for algorithms designed to detect a wide range of issues including fractures, dislocations, and other anatomical irregularities in X-ray images. This is the reason that makes us decide to get involved with **MuraMed**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d346328",
   "metadata": {},
   "source": [
    "#### Downloading the MURA Dataset\n",
    "---\n",
    "\n",
    "To download the MURA dataset for your own research or application, you can utilize the following Kaggle link: [Download MURA Dataset](https://www.kaggle.com/datasets/cjinny/mura-v11/download?datasetVersionNumber=1).\n",
    "\n",
    "Here's how you can do it:\n",
    "\n",
    "1. Navigate to the dataset page on Kaggle.\n",
    "2. Click on the \"Download\" button. This will download a ZIP file to your computer.\n",
    "3. Upload the ZIP file to your Jupyter Notebook environment.\n",
    "\n",
    "Or, to download directly in this Jupyter Notebook (remember to remove the comment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f9d0cf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MURA Dataset download through Kaggle.\n",
    "# !wget \"https://www.kaggle.com/datasets/cjinny/mura-v11/download?datasetVersionNumber=1\" -O MURA-v1.1.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b5a163",
   "metadata": {},
   "source": [
    "Please note that this command will download the ZIP file and name it `MURA-v1.1.zip`. The `-O` flag specifies the output file name.\n",
    "\n",
    "**_Important Note:_** The direct download link from Kaggle usually requires you to be logged in. Therefore, the above `wget` method might not work without proper authentication or cookies. In such cases, manual download and upload would be the straightforward approach.\n",
    "\n",
    "You can try to download the file through [Stanford's ML site](https://stanfordmlgroup.github.io/competitions/mura/)  To download the dataset you must first fill out a form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa431aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MURA Dataset download through Stanford ML.\n",
    "# !wget 'https://cs.stanford.edu/group/mlgroup/MURA-v1.1.zip' -O MURA-v1.1.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facd29f7",
   "metadata": {},
   "source": [
    "As is notated above, please note that this command will download the ZIP file and name it `MURA-v1.1.zip`. The `-O` flag specifies the output file name.\n",
    "\n",
    "**_Important Note:_** On a similare note the direct download link from Stanford's ML site might not work without proper authentication or cookies. In such cases, manual download and upload would be the straightforward approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26c79c9",
   "metadata": {},
   "source": [
    "#### Unzipping the MURA Dataset\n",
    "---\n",
    "\n",
    "However, if the `wget` command successfully downloads the ZIP file, you would proceed to unzip it in your Jupyter Notebook environment. You can use Python's `zipfile` library to extract the contents.\n",
    "\n",
    "Here's how you can do it (remove the comments):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55d7ccd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "\n",
    "# with zipfile.ZipFile('MURA-v1.1.zip', 'r') as zip_ref:\n",
    "#     zip_ref.extractall('MURA-v1.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f71bd3",
   "metadata": {},
   "source": [
    "This code will extract all the files from `MURA-v1.1.zip` into a directory named `MURA-v1.1`.\n",
    "\n",
    "After the dataset is successfully unzipped, you can proceed with the notebook as per the roadmap outlines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d8ba6a",
   "metadata": {},
   "source": [
    "### Setting the Seed for Reproducibility\n",
    "---\n",
    "\n",
    "In order to ensure that the experiments are reproducible, it is essential to set a seed for both NumPy and TensorFlow. By setting a seed, we ensure that the random numbers generated by these libraries are the same in every run. This is crucial for debugging and comparing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8964856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed value for reproducibility.\n",
    "SEED = 1001101\n",
    "\n",
    "# Setting the seed for NumPy.\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Setting the seed for TensorFlow.\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d883c2",
   "metadata": {},
   "source": [
    "By setting the seed value to *`1001101` (01001101 = Capital M in binary format)*, we ensure that the random processes in both NumPy and TensorFlow libraries will produce the same set of random numbers, thereby making the experiments reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de57e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Filepath for the MURA-v1.1 dataset\n",
    "filepath = 'MURA-v1.1'\n",
    "\n",
    "# Check if filepath exists\n",
    "if os.path.exists(filepath):\n",
    "    # Get train and test set filepaths\n",
    "    train_set_filepath = os.path.join(filepath, 'train_image_paths.csv')\n",
    "    test_set_filepath = os.path.join(filepath, 'valid_image_paths.csv')\n",
    "    \n",
    "    # Check if files exist\n",
    "    if not os.path.exists(train_set_filepath):\n",
    "        print(f\"Error: {train_set_filepath} does not exist.\")\n",
    "    if not os.path.exists(test_set_filepath):\n",
    "        print(f\"Error: {test_set_filepath} does not exist.\")\n",
    "else:\n",
    "    print(f\"Error: Directory {filepath} does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77160ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath:str):\n",
    "\n",
    "    # load data into a dataframe\n",
    "    df = pd.read_csv(filepath, header=None, names=['image_path'])\n",
    "\n",
    "    # create a description of the study of each image\n",
    "    df['description'] = df.image_path.apply(lambda x: '_'.join(x.split('/')[2:5])[3:])\n",
    "\n",
    "    # get the type of each study (e.g., elbow, shoulder, etc.)\n",
    "    df['type'] = df.description.apply(lambda x: x.split('_')[0])\n",
    "\n",
    "    # get the patient code of each study\n",
    "    df['patient'] = df.description.apply(lambda x: x.split('_')[1])\n",
    "\n",
    "    # get the code of each study\n",
    "    df['study'] = df.description.apply(lambda x: x.split('_')[2])\n",
    "\n",
    "    # get the opinion of each study\n",
    "    df['opinion'] = df.description.apply(lambda x: x.split('_')[3])\n",
    "\n",
    "    # create the label\n",
    "    df['label'] = np.where(df.opinion == 'positive',1,0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d6c52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "train_set = load_data(train_set_filepath)\n",
    "\n",
    "# shape\n",
    "print(f'train_set.shape: {train_set.shape}')\n",
    "\n",
    "# preview\n",
    "train_set.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2b76d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6),dpi=100)\n",
    "ax = sns.countplot(data=train_set, x=train_set['type'].sort_values(), hue=train_set['label'])\n",
    "ax.bar_label(ax.containers[0], padding=1)\n",
    "ax.bar_label(ax.containers[1], padding=1)\n",
    "plt.xlabel(None)\n",
    "plt.ylabel(None)\n",
    "plt.yticks([])\n",
    "plt.title('Number of normal and abnormal case studies per body part')\n",
    "plt.legend(loc=0, labels=['Normal','Abnormal'])\n",
    "plt.savefig('distribution_of_case_studies_per_body_part_train.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81b8953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "test_set = load_data(test_set_filepath)\n",
    "\n",
    "# shape\n",
    "print(f'test_set.shape: {test_set.shape}')\n",
    "\n",
    "# preview\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cb315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validation_split(dataset:pd.DataFrame):\n",
    "\n",
    "    # define x and y\n",
    "    x = dataset.drop(columns='label')\n",
    "    y = dataset.label\n",
    "\n",
    "    # split into training and validation sets\n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(x,\n",
    "                                                          y,\n",
    "                                                          test_size=0.2,\n",
    "                                                          shuffle=True,\n",
    "                                                          stratify=dataset[['label','type']],\n",
    "                                                          random_state=1)\n",
    "    \n",
    "    # concat x and y sets\n",
    "    train_set = pd.concat([x_train, y_train], axis=1)\n",
    "    valid_set = pd.concat([x_valid, y_valid], axis=1)\n",
    "\n",
    "    # preview the sizes\n",
    "    print(f'train_set.shape: {train_set.shape}')\n",
    "    print(f'valid_set.shape: {valid_set.shape}')\n",
    "\n",
    "    return train_set, valid_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f816d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute function\n",
    "train_set, valid_set = train_validation_split(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb82bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6),dpi=100)\n",
    "ax = sns.countplot(data=train_set, x=train_set['type'].sort_values(), color='lightblue', label='Train set')\n",
    "ax.bar_label(ax.containers[0], padding=1)\n",
    "ax = sns.countplot(data=valid_set, x=valid_set['type'].sort_values(), color='orange', label='Validation set')\n",
    "ax.bar_label(ax.containers[1], padding=1)\n",
    "plt.xlabel(None)\n",
    "plt.ylabel(None)\n",
    "plt.yticks([])\n",
    "plt.title('Number of case studies per body part')\n",
    "plt.legend()\n",
    "plt.savefig('number_of_case_studies_per_body_part_train.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f7d7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ImageDataGenerator object\n",
    "train_image_data_gen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    brightness_range=(0.8,1.2),\n",
    "    horizontal_flip=True,\n",
    "    rescale=random.uniform(0.95,1.3), # select random number between 0.95 and 1.3\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "# generate images\n",
    "train_data_gen = train_image_data_gen.flow_from_dataframe(\n",
    "    train_set,\n",
    "    x_col='image_path',\n",
    "    y_col='label',\n",
    "    target_size=(224,224), # the dimensions to which all images found will be resized\n",
    "    class_mode='raw', # numpy array of values in y_col column, need to use this if values in y_col are of type int\n",
    "    batch_size=64, # size of the batches of data\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7485cb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ImageDataGenerator object\n",
    "valid_image_data_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "# generate images\n",
    "valid_data_gen = valid_image_data_gen.flow_from_dataframe(\n",
    "    valid_set,\n",
    "    x_col='image_path',\n",
    "    y_col='label',\n",
    "    target_size=(224,224), # the dimensions to which all images found will be resized\n",
    "    class_mode='raw', # numpy array of values in y_col column, need to use this if values in y_col are of type int\n",
    "    batch_size=64, # size of the batches of data\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1884dd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ImageDataGenerator object\n",
    "test_image_data_gen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "# generate images\n",
    "test_data_gen = test_image_data_gen.flow_from_dataframe(\n",
    "    test_set,\n",
    "    x_col='image_path',\n",
    "    y_col='label',\n",
    "    target_size=(224,224), # the dimensions to which all images found will be resized\n",
    "    class_mode='raw', # numpy array of values in y_col column, need to use this if values in y_col are of type int\n",
    "    batch_size=64, # size of the batches of data\n",
    "    shuffle=False,\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c40418",
   "metadata": {},
   "source": [
    "cccccccccccccccccc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a77f70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape:tuple=(224,224,3),\n",
    "                learning_rate:float=1e-4,\n",
    "                conv_layers:int=1, # number of convolutional layers\n",
    "                conv_units:int=32, # number of neurons per convolutional layer\n",
    "                conv_activation:str='relu', # activation function for convolutional layers\n",
    "                hidden_dropout_prob:float=0.5, # dropout probability for neurons in hidden layers\n",
    "                hidden_units:int=256, # number of neurons per hidden layer\n",
    "                hidden_activation:str='relu', # activation function for hidden layers\n",
    "                output_activation:str='sigmoid', # activation function for output layer\n",
    "                metrics:list=['accuracy']\n",
    "               ):\n",
    "\n",
    "    # define the input layer\n",
    "    input = Input(\n",
    "            shape=input_shape, # input shape (number of features)\n",
    "            name='Input'\n",
    "    )\n",
    "    x = input\n",
    "    \n",
    "    # define the convolutional layers\n",
    "    for i in range(conv_layers):\n",
    "        \n",
    "        cnt = i # keep track of i\n",
    "        \n",
    "        # add conv2d layer\n",
    "        x = Conv2D(\n",
    "            filters=conv_units*(2**i),\n",
    "            kernel_size=(3,3),\n",
    "            strides=(1,1),\n",
    "            padding='same',\n",
    "            dilation_rate=(1,1),\n",
    "            activation=conv_activation,\n",
    "            name=f'Conv2D-{i+1}'\n",
    "        )(x)\n",
    "        \n",
    "        # add a batch normalization layer\n",
    "        x = BatchNormalization(\n",
    "            name=f'BatchNormalization-{i+1}'\n",
    "        )(x)\n",
    "        \n",
    "        # add max pooling layer\n",
    "        x = MaxPool2D(\n",
    "            pool_size=(2,2),\n",
    "            strides=(2,2),\n",
    "            padding='same',\n",
    "            name=f'MaxPool2D-{i+1}'\n",
    "        )(x)\n",
    "    \n",
    "    # flatten the convoled images\n",
    "    # so as to input them to a Dense Layer\n",
    "    x = Flatten(\n",
    "        name='Flatten'\n",
    "    )(x)\n",
    "    \n",
    "    # add dropout layer\n",
    "    x = Dropout(\n",
    "        rate=hidden_dropout_prob,\n",
    "        name=f'Dropout-1'\n",
    "    )(x)\n",
    "    \n",
    "    # add another dense layer\n",
    "    # before the output layer\n",
    "    x = Dense(\n",
    "        units=hidden_units,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        activation=hidden_activation,\n",
    "        name=f'Dense-1'\n",
    "    )(x)\n",
    "    \n",
    "    # add a batch normalization layer\n",
    "    x = BatchNormalization(\n",
    "        name=f'BatchNormalization-{cnt+2}'\n",
    "    )(x)\n",
    "    \n",
    "    # add dropout layer\n",
    "    x = Dropout(\n",
    "        rate=hidden_dropout_prob,\n",
    "        name=f'Dropout-2'\n",
    "    )(x)\n",
    "        \n",
    "    # define the output layer\n",
    "    output = Dense(\n",
    "             units=1, # predicted outcome\n",
    "             kernel_initializer='glorot_uniform',\n",
    "             activation=output_activation,\n",
    "             name='Output'\n",
    "    )(x)\n",
    "\n",
    "    # define the model\n",
    "    model = Model(inputs=input, outputs=output)\n",
    "    \n",
    "    # add L2 regularization to the convolutional and fully connected layers\n",
    "    l2_reg = l2(0.01)\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, Conv2D) or isinstance(layer, Dense):\n",
    "            layer.kernel_regularizer = l2_reg\n",
    "            \n",
    "    # compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=metrics)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43594574",
   "metadata": {},
   "source": [
    "callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91806fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    mode='min',\n",
    "    restore_best_weights=True,\n",
    "    verbose=1)\n",
    "\n",
    "# define ReduceLROnPlateau callback\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    mode='min',\n",
    "    factor=0.1,\n",
    "    min_lr=1e-10,\n",
    "    verbose=1)\n",
    "\n",
    "# define callbacks\n",
    "CALLBACKS = [early_stopping, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e927056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_data,\n",
    "                valid_data,\n",
    "                input_shape:tuple=(224,224,3),\n",
    "                learning_rate:float=1e-4,\n",
    "                conv_layers:int=1, # number of convolutional layers\n",
    "                conv_units:int=32, # number of neurons per convolutional layer\n",
    "                conv_activation:str='relu', # activation function for convolutional layers\n",
    "                hidden_dropout_prob:float=0.5, # dropout probability for neurons in hidden layers\n",
    "                hidden_units:int=256, # number of neurons per hidden layer\n",
    "                hidden_activation:str='relu', # activation function for hidden layers\n",
    "                output_activation:str='softmax', # activation function for output layer\n",
    "                metrics:list=['accuracy'],\n",
    "                batch_size=128,\n",
    "                epochs=20,\n",
    "                verbose=1,\n",
    "                callbacks:list=None\n",
    "               ):\n",
    "    \n",
    "    # build the model\n",
    "    model = build_model(input_shape,\n",
    "                        learning_rate,\n",
    "                        conv_layers, # number of convolutional layers, if 0 then equal to LogReg\n",
    "                        conv_units, # number of neurons per convolutional layer\n",
    "                        conv_activation, # activation function for convolutional layers\n",
    "                        hidden_dropout_prob, # boolean to define whether to add dropout\n",
    "                        hidden_units, # number of neurons per hidden layer\n",
    "                        hidden_activation, # activation function for hidden layers\n",
    "                        output_activation, # activation function for output layer\n",
    "                        metrics\n",
    "                       )\n",
    "    \n",
    "    print('Started training.')\n",
    "    print('-----------------')\n",
    "    print()\n",
    "    \n",
    "    # train the model\n",
    "    hs = model.fit(x=train_data,\n",
    "                   batch_size=batch_size,\n",
    "                   epochs=epochs,\n",
    "                   verbose=verbose,\n",
    "                   callbacks=callbacks,\n",
    "                   validation_data=valid_data\n",
    "                  )\n",
    "    \n",
    "    print()\n",
    "    print('Finished training.')\n",
    "    print('------------------')\n",
    "    print()\n",
    "    \n",
    "    return model, hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0923e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60801950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start time\n",
    "st = time.time()\n",
    "\n",
    "# execute function to train the model\n",
    "cnn_model, cnn_hs = train_model(train_data=train_data_gen,\n",
    "                                valid_data=valid_data_gen,\n",
    "                                epochs=1,\n",
    "                                callbacks=CALLBACKS\n",
    "                               )\n",
    "\n",
    "# end time\n",
    "et = time.time()\n",
    "\n",
    "print(f'Elapsed time: {int(et-st)} secs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583e5f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc56adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(cnn_model, to_file='cnn_model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f235ec6",
   "metadata": {},
   "source": [
    "## *Model Evaluation*\n",
    "\n",
    "- *In this step, we will evaluate the performance of our model*\n",
    "- *In particular, we will evaluate its performance both during the training phase and making predictions*\n",
    "- *For this reason, we will create a function which will help us to plot the learning curves*\n",
    "\n",
    "##### *Define a function to plot learning curves*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b390df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(hs, epochs, metric):\n",
    "    print()\n",
    "    plt.style.use('dark_background')\n",
    "    plt.rcParams['figure.figsize'] = [15, 8]\n",
    "    plt.rcParams['font.size'] = 16\n",
    "    plt.clf()\n",
    "    for label in hs:\n",
    "        plt.plot(hs[label].history[metric], label='{0:s} train {1:s}'.format(label, metric), linewidth=2)\n",
    "        plt.plot(hs[label].history['val_{0:s}'.format(metric)], label='{0:s} validation {1:s}'.format(label, metric), linewidth=2)\n",
    "    x_ticks = np.arange(0, epochs + 1, epochs / 10)\n",
    "    x_ticks [0] += 1\n",
    "    plt.xticks(x_ticks)\n",
    "    plt.ylim((0, 1))\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss' if metric=='loss' else 'Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'cnn_learning_curves_{metric}.svg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f046e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763380d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CNN History Results:\")\n",
    "print(\"---\")\n",
    "print(\"Train Loss     : {0:.5f}\".format(cnn_hs.history['loss'][-1]))\n",
    "print(\"Validation Loss: {0:.5f}\".format(cnn_hs.history['val_loss'][-1]))\n",
    "print(\"---\")\n",
    "print(\"Train Accuracy     : {0:.5f}\".format(cnn_hs.history['accuracy'][-1]))\n",
    "print(\"Validation Accuracy: {0:.5f}\".format(cnn_hs.history['val_accuracy'][-1]))\n",
    "\n",
    "# plot train and validation error per epoch\n",
    "plot_history(hs={'CNN': cnn_hs}, epochs=epochs, metric='loss')\n",
    "plot_history(hs={'CNN': cnn_hs}, epochs=epochs, metric='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f300a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on test data\n",
    "model_eval = cnn_model.evaluate(test_data_gen, verbose=2)\n",
    "\n",
    "# print results\n",
    "print()\n",
    "print(\"Test Loss         : {0:.5f}\".format(model_eval[0]))\n",
    "print(\"Test Accuracy     : {0:.5f}\".format(model_eval[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cc8593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "predictions = cnn_model.predict(test_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745b648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_each_study_type(test_set, predictions):\n",
    "\n",
    "    # append predictions to the test set\n",
    "    test_set['predictions'] = predictions.ravel()\n",
    "    test_set['predictions'] = np.where(test_set.predictions >= 0.5,1,0)\n",
    "\n",
    "    # list of distinct study types\n",
    "    study_types = sorted(test_set['type'].unique().tolist())\n",
    "\n",
    "    # loop through study types\n",
    "    for i, st in enumerate(study_types):\n",
    "\n",
    "        # keep records of the current study type\n",
    "        df_t = test_set[test_set['type']==st]\n",
    "\n",
    "        # evaluate model performance on the current study type\n",
    "        precision = precision_score(df_t.label.values, df_t.predictions.values)\n",
    "        recall = recall_score(df_t.label.values, df_t.predictions.values)\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "        accuracy = accuracy_score(df_t.label.values, df_t.predictions.values)\n",
    "        roc_auc = roc_auc_score(df_t.label.values, df_t.predictions.values)\n",
    "        cohen_kappa = cohen_kappa_score(df_t.label.values, df_t.predictions.values)\n",
    "\n",
    "        # print results\n",
    "        print(f\"{i+1} - Study Type: {st}\")\n",
    "        print(\"------------------------\")\n",
    "        print(f\"    Precision: {round(precision,5)}\")\n",
    "        print(f\"       Recall: {round(recall,5)}\")\n",
    "        print(f\"     F1 Score: {round(f1_score,5)}\")\n",
    "        print(f\"     Accuracy: {round(accuracy,5)}\")\n",
    "        print(f\"      ROC AUC: {round(roc_auc,5)}\")\n",
    "        print(f\"Cohen's Kappa: {round(cohen_kappa,5)}\")\n",
    "        print(\"========================\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c04cdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_each_study_type(test_set, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338e6b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0e838c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db19d276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1b2377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23d6cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8424bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adc9a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3211b266",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
